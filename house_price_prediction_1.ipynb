{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import date\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "#import seaborn as sns\n",
    "import mpl_toolkits\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.tools.plotting import lag_plot\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, Ridge, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score   # accuracy metrics\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.9557671546936\n"
     ]
    }
   ],
   "source": [
    "#extract the data from hm land registry using the selection criteria\n",
    "\n",
    "col_names = ['tui', 'price', 'txn_date', 'post_code', 'type', 'is_new','DURATION(F/L)','PAON', 'SAON', 'STREET',\n",
    "            'LOCALITY', 'town', 'district', 'county', 'cat', 'record_status']\n",
    "\n",
    "#read all data files into a single dataframe\n",
    "path = r'C:\\Users\\rajgu\\OneDrive\\Documents\\step_function\\house-price-prediction\\data'\n",
    "path_outcode = r'C:\\Users\\rajgu\\OneDrive\\Documents\\step_function\\house-price-prediction\\outcodes.csv'\n",
    "allFiles = glob.glob(path + \"/*.csv\")\n",
    "frame = pd.DataFrame()\n",
    "list_ = []\n",
    "t1 = time.time()\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,names = col_names)\n",
    "    list_.append(df)\n",
    "ppd_df = pd.concat(list_)\n",
    "print(time.time() - t1)\n",
    "\n",
    "filtered_df = ppd_df[(ppd_df.county == 'GREATER LONDON') & (ppd_df.type == 'T') & (ppd_df.cat == 'A') & (ppd_df.price < 5000000)\n",
    "                    & (ppd_df.price > 0)]\n",
    "\n",
    "#get the outcode df\n",
    "df_outcodes = pd.read_csv(path_outcode)\n",
    "#ppd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#utilities\n",
    "\n",
    "def postcode_to_outcode(post_code):\n",
    "    try:\n",
    "        return post_code.split(' ')[0]\n",
    "    except AttributeError:\n",
    "        print(post_code)\n",
    "\n",
    "#def distance_in_km(lat, lon, reflat = , reflat = 51.507602, reflon = -0.127816):\n",
    "def outcode_to_distance(row, ref_lat=51.507602, ref_lon=-0.127816 ):\n",
    "    lat = row['latitude']\n",
    "    lon = row['longitude']\n",
    "    return haversine(lon, lat, ref_lon, ref_lat)\n",
    "    \n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    # Radius of earth in kilometers is 6371\n",
    "    km = 6371* c\n",
    "    return km\n",
    "\n",
    "def type_to_numerical(my_type):\n",
    "    value = 0\n",
    "    if(my_type == 'D'):\n",
    "        value = 1\n",
    "    elif(my_type == 'S'):\n",
    "        value = 2\n",
    "    elif(my_type == 'T'):\n",
    "        value = 3\n",
    "    elif (my_type == 'F'):\n",
    "        value = 4\n",
    "    return value\n",
    "        \n",
    "        \n",
    "def price_in_000(price):\n",
    "    return price/1000.0\n",
    "\n",
    "def mth_yr(date):\n",
    "    split = date.split('-')\n",
    "    return (split[0] + split[1])\n",
    "\n",
    "def mth_yr1(my_date):\n",
    "    split = my_date.split('-')\n",
    "    new_date = date(int(split[0]), int(split[1]), 1)\n",
    "    return new_date\n",
    "\n",
    "def date_diff_days(earlier_date, later_date):\n",
    "    date_diff = abs(later_date - earlier_date)\n",
    "    return date_diff.days\n",
    "\n",
    "def date_diff_days1(my_date):\n",
    "    ref_date = date(2003, 12, 1)\n",
    "    date_diff = abs(my_date - ref_date)\n",
    "    return date_diff.days\n",
    "\n",
    "def log_series(series):\n",
    "    return np.log(series)\n",
    "\n",
    "def pct_chg(series):\n",
    "    return tuple(pd.Series.pct_change(series).values.tolist())\n",
    "\n",
    "def is_outlier(points, thresh=3.5):\n",
    "    \"\"\"\n",
    "    Returns a boolean array with True if points are outliers and False \n",
    "    otherwise.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        points : An numobservations by numdimensions array of observations\n",
    "        thresh : The modified z-score to use as a threshold. Observations with\n",
    "            a modified z-score (based on the median absolute deviation) greater\n",
    "            than this value will be classified as outliers.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        mask : A numobservations-length boolean array.\n",
    "\n",
    "    References:\n",
    "    ----------\n",
    "        Boris Iglewicz and David Hoaglin (1993), \"Volume 16: How to Detect and\n",
    "        Handle Outliers\", The ASQC Basic References in Quality Control:\n",
    "        Statistical Techniques, Edward F. Mykytka, Ph.D., Editor. \n",
    "    \"\"\"\n",
    "    \n",
    "    points = np.array(points)\n",
    "    if len(points.shape) == 1:\n",
    "        points = points[:,None]\n",
    "    median = np.median(points, axis=0)\n",
    "    diff = np.sum((points - median)**2, axis=-1)\n",
    "    diff = np.sqrt(diff)\n",
    "    med_abs_deviation = np.median(diff)\n",
    "\n",
    "    modified_z_score = 0.6745 * diff / med_abs_deviation\n",
    "\n",
    "    return modified_z_score > thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajgu\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\rajgu\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\rajgu\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\rajgu\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\rajgu\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#engineer the dataset to meet our requirements\n",
    "\n",
    "filtered_df['out_code'] = filtered_df['post_code'].apply(postcode_to_outcode)\n",
    "filtered_df['price_scaled'] = filtered_df['price'].apply(price_in_000)\n",
    "filtered_df['txn_mth'] = filtered_df['txn_date'].apply(mth_yr1)\n",
    "filtered_df['txn_days'] = filtered_df['txn_mth'].apply(date_diff_days1)\n",
    "filtered_df['type_num'] = filtered_df['type'].apply(type_to_numerical)\n",
    "\n",
    "df_outcodes = df_outcodes.rename(columns = {'postcode':'out_code'})\n",
    "merged_df = pd.merge(filtered_df, df_outcodes, on='out_code')\n",
    "\n",
    "merged_df['distance'] = merged_df.apply(outcode_to_distance, axis=1)\n",
    "merged_df = merged_df[merged_df.distance < 100]\n",
    "\n",
    "#dummy df for new builds\n",
    "dummy_df = pd.get_dummies(merged_df['is_new'])\n",
    "merged_df = pd.concat([merged_df, dummy_df], axis=1)\n",
    "merged_df = merged_df.rename(columns = {'Y':'d_newbuild', 'N':'d_old'})\n",
    "\n",
    "trunc_df = merged_df[['txn_days', 'distance', 'd_newbuild', 'd_old','price_scaled']]\n",
    "sorted_df = trunc_df.sort_values('txn_days') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training and validation\n",
      "(279844, 2) (69961, 2)\n",
      "Linear Regression Model\n",
      "[ 0.00015657 -0.06480541] 6.33418504399\n",
      "0.455937619182\n",
      "Ridge Regression\n",
      "[ 0.00015657 -0.0648054 ] 6.33418498725\n",
      "0.45593761942\n",
      "Decision Tree Regression\n",
      "0.535295119302\n",
      "Random Forest Regression\n",
      "[ 0.2404924  0.7595076]\n",
      "0.738208795518\n"
     ]
    }
   ],
   "source": [
    "#validation and overall accuracy comparison\n",
    "\n",
    "X = np.array(sorted_df[['txn_days','distance']])\n",
    "y = np.array(sorted_df['price_scaled'].apply(log_series))\n",
    "\n",
    "#define the training, validation and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "print('Model training and validation')\n",
    "print(X_train.shape, X_valid.shape)\n",
    "\n",
    "#test the linear regression model\n",
    "print(\"Linear Regression Model\")\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print(model.coef_, model.intercept_)\n",
    "print(model.score(X_valid, y_valid))\n",
    "\n",
    "#test the Ridge regression model\n",
    "print(\"Ridge Regression\")\n",
    "model_ridge = Ridge(alpha = 0.5)\n",
    "model_ridge.fit(X_train, y_train)\n",
    "print(model_ridge.coef_, model_ridge.intercept_)\n",
    "print(model_ridge.score(X_valid, y_valid))\n",
    "\n",
    "#decision trees\n",
    "print(\"Decision Tree Regression\")\n",
    "model_dt = DecisionTreeRegressor(max_depth=4)\n",
    "model_dt.fit(X_train, y_train)\n",
    "print(model_dt.score(X_valid, y_valid))\n",
    "\n",
    "#random forest\n",
    "print(\"Random Forest Regression\")\n",
    "regr = RandomForestRegressor(n_estimators=150, min_samples_split=4, min_samples_leaf=10)\n",
    "regr.fit(X_train, y_train)\n",
    "print(regr.feature_importances_)\n",
    "print(regr.score(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model testing\n",
      "(87452, 2)\n",
      "Linear Regression Model\n",
      "0.460358359104\n",
      "Ridge Regression\n",
      "0.460358359196\n",
      "Decision Tree Regression\n",
      "0.543745696964\n",
      "Random Forest Regression\n",
      "0.744956534008\n"
     ]
    }
   ],
   "source": [
    "print('Model testing')\n",
    "\n",
    "print(X_test.shape)\n",
    "\n",
    "print(\"Linear Regression Model\")\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "#test the Ridge regression model\n",
    "print(\"Ridge Regression\")\n",
    "print(model_ridge.score(X_test, y_test))\n",
    "\n",
    "#decision trees\n",
    "print(\"Decision Tree Regression\")\n",
    "print(model_dt.score(X_test, y_test))\n",
    "\n",
    "#random forest\n",
    "print(\"Random Forest Regression\")\n",
    "print(regr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
